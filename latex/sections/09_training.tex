%==============================================================================
% SECTION 9: TRAINING FRAMEWORK
%==============================================================================

\subsection{Training Framework}
\label{sec:training}

This section describes the training methodology for MofNeuroSim, enabling gradient-based learning while maintaining the pure SNN constraint. The key challenge is computing gradients through discrete spike operations.

\subsubsection{Straight-Through Estimator (STE)}

The Heaviside step function $\heaviside(\cdot)$ has zero gradient almost everywhere, preventing standard backpropagation. We address this using the Straight-Through Estimator (STE) as given by Equation~\ref{eq:ste}:

\begin{equation}
\frac{\partial \heaviside(x)}{\partial x} \approx 1
\label{eq:ste}
\end{equation}
where the Heaviside gradient is approximated as unity for gradient flow.

\paragraph{Forward Pass}
The forward pass uses discrete spikes as normal as given by Equation~\ref{eq:ste_forward}:

\begin{equation}
y = \heaviside(x - \threshold)
\label{eq:ste_forward}
\end{equation}
where $x$ denotes the membrane potential, $\threshold$ denotes the firing threshold, and $y \in \{0, 1\}$ denotes the spike output.

\paragraph{Backward Pass}
The backward pass treats $\heaviside$ as identity for gradient computation as given by Equation~\ref{eq:ste_backward}:

\begin{equation}
\frac{\partial L}{\partial x} = \frac{\partial L}{\partial y} \cdot \frac{\partial y}{\partial x} \approx \frac{\partial L}{\partial y} \cdot 1 = \frac{\partial L}{\partial y}
\label{eq:ste_backward}
\end{equation}
where $L$ denotes the loss function and the gradient passes through unchanged.

\subsubsection{Training Modes}

MofNeuroSim supports multiple training modes through the \texttt{TrainingMode} enumeration:

\begin{itemize}
    \item \textbf{TrainingMode.NONE}: Pure inference mode (default). No gradient tracking.
    \item \textbf{TrainingMode.STE}: Bit-exact STE training. Forward and backward use SNN components with STE gradients.
    \item \textbf{TrainingMode.TEMPORAL}: Temporal dynamics training (future extension). Exploits spike timing for learning.
\end{itemize}

\subsubsection{Implemented STE Functions}

The framework provides 16 STE functions covering all common neural network operations:

\begin{table}[h]
\centering
\small
\begin{tabular}{@{}ll@{}}
\toprule
\textbf{Category} & \textbf{STE Functions} \\
\midrule
Linear & \texttt{STELinearFunction}, \texttt{STEEmbeddingFunction} \\
Normalization & \texttt{STERMSNormFunction}, \texttt{STELayerNormFunction} \\
Activation & \texttt{STEExpFunction}, \texttt{STESigmoidFunction}, \\
           & \texttt{STETanhFunction}, \texttt{STESiLUFunction}, \\
           & \texttt{STEGELUFunction}, \texttt{STESoftmaxFunction}, \\
           & \texttt{STEReLUFunction} \\
Arithmetic & \texttt{STEMulFunction}, \texttt{STEAddFunction} \\
Control & \texttt{STEMUXFunction} \\
Position & \texttt{STERoPEFunction} \\
Boundary & \texttt{STEDecodeFunction} \\
\bottomrule
\end{tabular}
\caption{Complete list of STE functions in MofNeuroSim}
\label{tab:ste_functions}
\end{table}

\subsubsection{Pure Pulse Architecture}

In STE training mode, the entire computation graph operates in the pulse domain as illustrated by Equation~\ref{eq:pulse_graph}:

\begin{equation}
\text{Float} \xrightarrow{\text{encode}} \pulse{x} \xrightarrow{\text{SNN}} \pulse{y} \xrightarrow{\text{decode}} \text{Float} \xrightarrow{\text{loss}} \mathcal{L}
\label{eq:pulse_graph}
\end{equation}
where $\pulse{x}$ denotes the pulse-encoded input, $\pulse{y}$ denotes the pulse-encoded output, and $\mathcal{L}$ denotes the loss value.

\paragraph{Weight Storage}
Weights are stored directly as pulse sequences as given by Equation~\ref{eq:train_weight}:

\begin{equation}
\pulse{\mathbf{W}} \in \{0,1\}^{D_{out} \times D_{in} \times n}
\label{eq:train_weight}
\end{equation}
where $\pulse{\mathbf{W}}$ denotes the pulse-encoded weight tensor, $D_{out}$ denotes the output dimension, $D_{in}$ denotes the input dimension, and $n$ denotes the bit width. This is a trainable parameter with gradients computed through STE.

\paragraph{Boundary Operations}
Encoding and decoding occur only at system boundaries:

\begin{itemize}
    \item \textbf{Input encoding}: $\pulse{x} = \text{encode}(x)$ at model input
    \item \textbf{Output decoding}: $y = \text{decode}(\pulse{y})$ at model output for loss computation
\end{itemize}

The \texttt{ste\_decode} function performs decoding with gradient passthrough as given by Equation~\ref{eq:ste_decode}:

\begin{equation}
\text{ste\_decode}(\pulse{x}) = \text{decode}(\pulse{x}), \quad \frac{\partial}{\partial \pulse{x}} = \text{encode}(\nabla_y)
\label{eq:ste_decode}
\end{equation}
where $\pulse{x}$ denotes the pulse input, $\text{decode}(\cdot)$ denotes the decoding function, and $\nabla_y$ denotes the gradient of the loss with respect to the output.

\subsubsection{PulseSGD Optimizer}

We introduce PulseSGD, a gradient descent optimizer that operates entirely in the pulse domain as given by Equation~\ref{eq:pulse_sgd}:

\begin{equation}
\pulse{\mathbf{W}}^{(t+1)} = \pulse{\mathbf{W}}^{(t)} - \eta \cdot \pulse{\nabla \mathcal{L}}
\label{eq:pulse_sgd}
\end{equation}
where $\pulse{\mathbf{W}}^{(t)}$ denotes the pulse-encoded weights at iteration $t$, $\eta$ denotes the learning rate, and $\pulse{\nabla \mathcal{L}}$ denotes the pulse-encoded gradient.

\paragraph{Algorithm}
The update proceeds as: decode current weights ($\mathbf{W} = \text{decode}(\pulse{\mathbf{W}})$), decode gradients ($\nabla \mathcal{L} = \text{decode}(\pulse{\nabla \mathcal{L}})$), compute update ($\mathbf{W}' = \mathbf{W} - \eta \cdot \nabla \mathcal{L}$), then encode new weights ($\pulse{\mathbf{W}}' = \text{encode}(\mathbf{W}')$).

\paragraph{Momentum Extension}
PulseSGD with momentum is given by Equation~\ref{eq:pulse_momentum}:

\begin{align}
\mathbf{v}^{(t+1)} &= \beta \mathbf{v}^{(t)} + \nabla \mathcal{L}^{(t)} \nonumber \\
\pulse{\mathbf{W}}^{(t+1)} &= \pulse{\mathbf{W}}^{(t)} - \eta \cdot \text{encode}(\mathbf{v}^{(t+1)})
\label{eq:pulse_momentum}
\end{align}
where $\mathbf{v}^{(t)}$ denotes the velocity at iteration $t$, $\beta$ denotes the momentum coefficient, $\nabla \mathcal{L}^{(t)}$ denotes the gradient at iteration $t$, $\eta$ denotes the learning rate, and $\text{encode}(\cdot)$ denotes the pulse encoding function.

\subsubsection{SNN Backward Components}

All backward computations share a set of SNN components managed by a singleton \texttt{SNNBackwardComponents} class. This includes:

\begin{itemize}
    \item \textbf{VecMul}: Element-wise multiplication
    \item \textbf{VecAdd/VecSub}: Element-wise addition/subtraction
    \item \textbf{VecDiv}: Element-wise division
    \item \textbf{MatMulT}: Matrix multiplication with transposed weight
    \item \textbf{OuterProduct}: Outer product for weight gradients
    \item \textbf{VecAND}: Bitwise AND for masking operations
\end{itemize}

\subsubsection{Parallel Tree Reduction}

Sum operations in backward passes use parallel tree reduction as given by Equation~\ref{eq:tree_reduce}:

\begin{equation}
\text{reduce}(\{x_1, \ldots, x_n\}) = \text{reduce}(\{x_1+x_2, x_3+x_4, \ldots\})
\label{eq:tree_reduce}
\end{equation}
where pairs are summed in parallel at each level, reducing depth from $O(n)$ to $O(\log n)$.

\subsubsection{Gradient Flow Through SNN Layers}

\paragraph{Linear Layer}
For $\mathbf{y} = \mathbf{x} \mathbf{W}^T$, the gradients are computed as given by Equation~\ref{eq:linear_grad}:

\begin{align}
\frac{\partial \mathcal{L}}{\partial \mathbf{W}} &= \left(\frac{\partial \mathcal{L}}{\partial \mathbf{y}}\right)^T \mathbf{x} \nonumber \\
\frac{\partial \mathcal{L}}{\partial \mathbf{x}} &= \frac{\partial \mathcal{L}}{\partial \mathbf{y}} \mathbf{W}
\label{eq:linear_grad}
\end{align}
where $\mathcal{L}$ denotes the loss, $\mathbf{W}$ denotes the weight matrix, $\mathbf{x}$ denotes the input, $\mathbf{y}$ denotes the output, and $\frac{\partial \mathcal{L}}{\partial \mathbf{y}}$ denotes the upstream gradient. These matrix multiplications use the same SNN operators as forward pass.

\paragraph{Activation Functions}
Activation gradients are computed using SNN arithmetic:

\begin{itemize}
    \item \textbf{Sigmoid}: $\frac{\partial}{\partial x}\sigma(x) = \sigma(x)(1 - \sigma(x))$
    \item \textbf{Tanh}: $\frac{\partial}{\partial x}\tanh(x) = 1 - \tanh^2(x)$
    \item \textbf{SiLU}: $\frac{\partial}{\partial x}\text{SiLU}(x) = \sigma(x) + x \cdot \sigma(x)(1 - \sigma(x))$
    \item \textbf{GELU}: $\frac{\partial}{\partial x}\text{GELU}(x) = \sigma(kx) + kx \cdot \sigma(kx)(1 - \sigma(kx))$, where $k=1.702$
    \item \textbf{ReLU}: $\frac{\partial}{\partial x}\text{ReLU}(x) = \heaviside(x)$
    \item \textbf{Exp}: $\frac{\partial}{\partial x}e^x = e^x$
\end{itemize}

\paragraph{Softmax}
The softmax backward is computed as given by Equation~\ref{eq:softmax_grad}:

\begin{equation}
\frac{\partial \mathcal{L}}{\partial x_i} = y_i \left( \frac{\partial \mathcal{L}}{\partial y_i} - \sum_j \frac{\partial \mathcal{L}}{\partial y_j} y_j \right)
\label{eq:softmax_grad}
\end{equation}
where $y_i = \text{softmax}(x)_i$ denotes the softmax output and the sum is computed via parallel tree reduction.

\paragraph{RMSNorm}
The RMSNorm backward includes a Jacobian correction term as given by Equation~\ref{eq:rmsnorm_grad}:

\begin{align}
\frac{\partial \mathcal{L}}{\partial \mathbf{x}} &= \frac{\partial \mathcal{L}}{\partial \mathbf{y}} \odot \boldsymbol{\gamma} \cdot \text{rms}^{-1} - \mathbf{x} \cdot \text{rms}^{-3} \cdot \frac{1}{n} \sum_i \left( \frac{\partial \mathcal{L}}{\partial y_i} \gamma_i x_i \right) \nonumber \\
\frac{\partial \mathcal{L}}{\partial \boldsymbol{\gamma}} &= \sum_{\text{batch}} \frac{\partial \mathcal{L}}{\partial \mathbf{y}} \odot \hat{\mathbf{x}}
\label{eq:rmsnorm_grad}
\end{align}
where $\text{rms} = \sqrt{\frac{1}{n}\sum_i x_i^2 + \epsilon}$, $\hat{\mathbf{x}} = \mathbf{x}/\text{rms}$ denotes the normalized input, $\boldsymbol{\gamma}$ denotes the scale parameter, and $\odot$ denotes element-wise multiplication. The second term in $\frac{\partial \mathcal{L}}{\partial \mathbf{x}}$ accounts for the dependence of rms on $\mathbf{x}$.

\paragraph{RoPE (Rotary Position Embedding)}
The RoPE backward reverses the rotation as given by Equation~\ref{eq:rope_grad}:

\begin{align}
\frac{\partial \mathcal{L}}{\partial x_{2i-1}} &= \frac{\partial \mathcal{L}}{\partial x'_{2i-1}} \cos\theta + \frac{\partial \mathcal{L}}{\partial x'_{2i}} \sin\theta \nonumber \\
\frac{\partial \mathcal{L}}{\partial x_{2i}} &= \frac{\partial \mathcal{L}}{\partial x'_{2i}} \cos\theta - \frac{\partial \mathcal{L}}{\partial x'_{2i-1}} \sin\theta
\label{eq:rope_grad}
\end{align}
where $x'$ denotes the rotated output and $\theta$ denotes the rotation angle. This is the transpose of the forward rotation matrix.

\subsubsection{Training Loop}

A typical training iteration proceeds as: reset membrane potentials in all stateful modules, encode input batch to pulse format ($\pulse{\mathbf{x}}$), forward propagate through SNN layers ($\pulse{\mathbf{y}}$), decode output to float ($\mathbf{y}$) for loss computation ($\mathcal{L}$), backward propagate gradients with STE, then apply PulseSGD to update pulse weights.

\subsubsection{Convergence Properties}

The STE approximation introduces a bias in gradient estimates. However, empirical results show that training converges for standard architectures, final accuracy approaches float-trained models, and bit-exact inference is preserved after training.

\subsubsection{Parameter Access}

Trainable modules provide the \texttt{pulse\_parameters()} method to access pulse-format parameters as given by Equation~\ref{eq:pulse_params}:

\begin{equation}
\texttt{pulse\_parameters()} \rightarrow \{\pulse{\mathbf{W}}, \pulse{\mathbf{b}}, \ldots\}
\label{eq:pulse_params}
\end{equation}
where $\pulse{\mathbf{W}}$ denotes the pulse-encoded weights and $\pulse{\mathbf{b}}$ denotes the pulse-encoded biases.

This is analogous to PyTorch's \texttt{parameters()} but returns pulse tensors for use with PulseSGD.

\subsubsection{Future Extensions}

\paragraph{Temporal Training Mode}
The TEMPORAL training mode will exploit spike timing dynamics including Spike-Timing-Dependent Plasticity (STDP), temporal credit assignment, and online learning rules.

\paragraph{Hardware-Aware Training}
Quantization-aware training for specific neuromorphic hardware addresses weight precision constraints, neuron count budgets, and power consumption optimization.

